{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GRASPy as gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation can be found here - https://sebporras.github.io/GRASPy/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a local instance of GServer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At time of writing, an instance of GServer is running on bioinfr (10.139.1.21 - port 4072). To make requests, you will need to be connected to the UQ network (on campus or *via* VPN). Note that the above IP address must be specified in the ```sendRequest``` function within ```GRASPy.client``` to run jobs using this instance.<br><br>\n",
    "**However, setting up a local GServer instance is currently the preferred option.** Simply obtain a JAR file for the current version of ```bnkit```, and run the following command:<br><br>\n",
    "```java -cp bnkit.jar asr.GServer```<br><br>\n",
    "Note that the IP address variable in the ```sendRequest``` function within ```GRASPy.client``` should be set to \"localhost\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing joint reconstructions.\n",
    "\n",
    "Step 1) Submit the job to the server. You should specify either Protein, DNA or RNA but it will try guess the sequnce type if you forget. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = gp.JointReconstruction(aln=\"./example_data/joint_recon/GRASPTutorial_Final.aln\",\n",
    "                                nwk=\"./example_data/joint_recon/GRASPTutorial_Final.nwk\", \n",
    "                                alphabet=\"Protein\")\n",
    "\n",
    "job_id = request[\"Job\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2) Find out where your job is in the queue or the status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#queue = g_requests.PlaceInQueue(job_id)\n",
    "status = gp.JobStatus(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3) Retrieve your job which will have the POG graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = gp.JobOutput(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4 - Optional) Request POGs for extant sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extant_tree = gp.ExtantPOGTree(aln=\"./example_data/big_test_data/GRASPTutorial_Final.aln\",\n",
    "nwk=\"./test_data/big_test_data/GRASPTutorial_Final.nwk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extant_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5 - Option 1) Build a POG tree from extant and ancesor POGs using both of the server outputs \n",
    "\n",
    "- The advantage of doing it this way is that the POGTree object will contain sequence information on the BranchPoints for ancestors AND extants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = gp.POGTreeFromJointReconstruction(extant_tree, graphs)\n",
    "\n",
    "tree.branchpoints[\"XP_012687241.1\"].seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5 - Option 2) Build a POGTree from the ancestor POG and from a nwk file string \n",
    "\n",
    "- ONLY ancestors will have sequence information based on the most likely symbol at each position in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = gp.POGTreeFromJointReconstruction(nwk=\"./example_data/joint_recon/GRASPTutorial_Final.nwk\", POG_graphs=graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.writeToNwk(file_name=\"test_nwk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning distributions from data \n",
    "\n",
    "The following instructions demonstrate how to learn a probability distribution from data. I need to add option to change some of the parameters as currently just runs on default settings. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1) Send request to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GRASPy as gp \n",
    "\n",
    "request_2 = gp.LearnLatentDistributions(nwk=\"./example_data/EMTrain/3_2_1_1_filt.nwk\", \n",
    "                                        states=[\"A\", \"B\"],                                        \n",
    "                                        csv_data=\"./example_data/EMTrain/3_2_1_1_data.csv\")\n",
    "\n",
    "second_id = request_2[\"Job\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2) Check the status of your job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = gp.PlaceInQueue(second_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3) Retrieve your job and save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = gp.JobOutput(second_id)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4) The learnt distribution can then be marginalised on an ancestor node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_distrib = out[\"Result\"][\"Distrib\"]\n",
    "\n",
    "infer = gp.MarginaliseDistOnAncestor(nwk=\"./example_data/EMTrain/3_2_1_1_filt.nwk\", \n",
    "                        states=[\"A\", \"B\"], \n",
    "                        csv_data=\"./example_data/EMTrain/3_2_1_1_data.csv\",\n",
    "                        distrib=j_distrib,\n",
    "                        ancestor=0)\n",
    "\n",
    "job_three_id = infer[\"Job\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infered_distribution = gp.JobOutput(job_three_id)\n",
    "\n",
    "infered_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference of sequence motifs *via* evolutionary modes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates the learning, and subsequent utilisation of, statistical parameters for evolutionary 'modes' for motif data. Here, we focus on a single mode, with very simple example data.<br><br>\n",
    "Two separate commands are communicated to the server: one for training the underlying 'phylogenetic plate' using known sequence data, and another which uses the learned distribution paraeters to infer marginal probability distributions for motif characters at an unobserved (possibly ancestral) node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GRASPy as gp\n",
    "\n",
    "files = 'example_data/Modes/'  # example file path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training modes from observed motif data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Sending the request to the server<br>***\n",
    "The function ```gp.TrainModes``` takes an input phylogenetic tree, observations for some (or all) sequences (in this case, characters observed in the given motif positions of an alignment), desired number of values taken by the latent state, and other optional inputs. A JSON request is then passed to the server, and optimised mixture distribution parameters are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to server...\n",
      "\n",
      "Socket connected to localhost on IP 4072\n",
      "\n",
      "{'Message': 'Queued', 'Job': 10}\n"
     ]
    }
   ],
   "source": [
    "# Request for training mode distribution parameters from known data (i.e. motif sequences of extants)\n",
    "request = gp.TrainModes(nwk=files+'motif_eg.nwk',       # tree\n",
    "                        csv_data=files+'motif_eg.csv',  # motif sequence data (from alignment)\n",
    "                        n_latent=2)                     # number of values taken by the latent state\n",
    "\n",
    "# Request will be 'queued' (but most likely run almost instantly) - server will return the job number\n",
    "job_id = request[\"Job\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Obtain output for the job***<br>\n",
    "The JSON output below specifies distribution parameters for amino acid characters at each motif position, conditioned on a latent state. Briefly, the number and names of latent states appear in the 'Modetypes' parameters. A set (length equal to the number of latent values) of distributions is provided for each position. These are conditioned on the latent state, and indexed corresponding to the order in which latent values appear. Residue probabilities appear in alphabetical order corresponding to their single-letter code, and concluding with the gap character **-**). We store these parameters for subsequent inference at unobserved nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to server...\n",
      "\n",
      "Socket connected to localhost on IP 4072\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Job': 10,\n",
       " 'Result': {'Distrib': {'Targets': [[0], [0], [0]],\n",
       "   'Modetypes': [{'Size': 2, 'Values': ['A', 'B'], 'Datatype': 'String'}],\n",
       "   'Nodes': [{'Condition': [['A'], ['B']],\n",
       "     'Pr': [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n",
       "     'Variable': {'Domain': {'Predef': 'Protein with gap'},\n",
       "      'Name': 'A__Feature1'},\n",
       "     'Nodetype': 'CPT',\n",
       "     'Index': [0, 1]},\n",
       "    {'Condition': [['A'], ['B']],\n",
       "     'Pr': [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "     'Variable': {'Domain': {'Predef': 'Protein with gap'},\n",
       "      'Name': 'A__Feature2'},\n",
       "     'Nodetype': 'CPT',\n",
       "     'Index': [0, 1]},\n",
       "    {'Condition': [['A'], ['B']],\n",
       "     'Pr': [[0.5,\n",
       "       0.5,\n",
       "       0,\n",
       "       0,\n",
       "       0,\n",
       "       0,\n",
       "       0,\n",
       "       0,\n",
       "       0,\n",
       "       0,\n",
       "       0,\n",
       "       0,\n",
       "       0,\n",
       "       0,\n",
       "       0,\n",
       "       0,\n",
       "       0,\n",
       "       0,\n",
       "       0,\n",
       "       0,\n",
       "       0],\n",
       "      [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "     'Variable': {'Domain': {'Predef': 'Protein with gap'},\n",
       "      'Name': 'A__Feature3'},\n",
       "     'Nodetype': 'CPT',\n",
       "     'Index': [0, 1]}],\n",
       "   'Name': 'A'}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = gp.JobOutput(job_id)\n",
    "distrib = output[\"Result\"][\"Distrib\"]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferring marginal probabilities of motifs for unobserved nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Sending the request to the server<br>***\n",
    "The function ```gp.InferModes``` takes the same input phylogenetic tree, and observations used to train modes. The distribution parameters obtained from training are also provided, as well as a list of query nodes for which sequence data should not have been observed during training. Marginal inference of latent state probabilities for each query node is performed independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to server...\n",
      "\n",
      "Socket connected to localhost on IP 4072\n",
      "\n",
      "{'Message': 'Queued', 'Job': 11}\n"
     ]
    }
   ],
   "source": [
    "request = gp.InferModesMarginal(nwk=files+'motif_eg.nwk',\n",
    "                                csv_data=files+'motif_eg.csv',\n",
    "                                distrib=distrib,\n",
    "                                query_nodes=['N0', 'N1']  # Sequence labels if leaves, or ancestor numbers for ancestors\n",
    "                               )\n",
    "\n",
    "job_id = request[\"Job\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Obtain output for the job***<br>\n",
    "The JSON output below specifies an inferred marginal probability distribution over latent states at the root node (*N0*) of our example tree. Probabilities over latent state characters are provided in the \"Pr\" list(s), and indexed according to the list of values (\"Values\" list). When multiple queries are made, distributions are listed sequentially and indexed according to the \"Items\" list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to server...\n",
      "\n",
      "Socket connected to localhost on IP 4072\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Job': 11,\n",
       " 'Result': {'Predict': {'Items': ['N0', 'N1'],\n",
       "   'Features': ['State 0'],\n",
       "   'Data': [[[{'Pr': [0.2981933243304438, 0.7018066756695562],\n",
       "       'Domain': {'Size': 2, 'Values': ['A', 'B'], 'Datatype': 'String'}}],\n",
       "     [{'Pr': [0.5105161855728779, 0.489483814427122],\n",
       "       'Domain': {'Size': 2, 'Values': ['A', 'B'], 'Datatype': 'String'}}]]]}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference = gp.JobOutput(job_id)\n",
    "inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Calculate amino acid distributions at each position***<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginal probabilities over sequence characters at the query node can be obtained by the law of total probability.\n",
    "For instance, to infer the probability of a character, $X$, at feature/position 1 ($F1$) in this example:\n",
    "<br><br>\n",
    "$$ P(F1=X) = P(L=A)\\cdot P(F1=X|L=A) + P(L=B) \\cdot P(F1=X|L=B) $$\n",
    "<br>\n",
    "where $L$ is the latent state value, and conditional distributions correspond to those obtained from training.<br><br>\n",
    "The function ```gp.motifProbsFromInference``` takes conditional distributions (learned from training) and inferred latent state probabilities, and provides a probability distribution over the amnio acids for each motif position, for each query node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N0': {'Feature1': {'A': 0.0,\n",
       "   'C': 0.0,\n",
       "   'D': 0.0,\n",
       "   'E': 0.0,\n",
       "   'F': 0.0,\n",
       "   'G': 0.2981933243304438,\n",
       "   'H': 0.0,\n",
       "   'I': 0.0,\n",
       "   'K': 0.0,\n",
       "   'L': 0.0,\n",
       "   'M': 0.0,\n",
       "   'N': 0.0,\n",
       "   'P': 0.0,\n",
       "   'Q': 0.0,\n",
       "   'R': 0.0,\n",
       "   'S': 0.0,\n",
       "   'T': 0.0,\n",
       "   'V': 0.0,\n",
       "   'W': 0.0,\n",
       "   'Y': 0.7018066756695562,\n",
       "   '-': 0.0},\n",
       "  'Feature2': {'A': 0.0,\n",
       "   'C': 0.0,\n",
       "   'D': 0.0,\n",
       "   'E': 0.0,\n",
       "   'F': 0.0,\n",
       "   'G': 0.2981933243304438,\n",
       "   'H': 0.0,\n",
       "   'I': 0.0,\n",
       "   'K': 0.0,\n",
       "   'L': 0.0,\n",
       "   'M': 0.0,\n",
       "   'N': 0.0,\n",
       "   'P': 0.7018066756695562,\n",
       "   'Q': 0.0,\n",
       "   'R': 0.0,\n",
       "   'S': 0.0,\n",
       "   'T': 0.0,\n",
       "   'V': 0.0,\n",
       "   'W': 0.0,\n",
       "   'Y': 0.0,\n",
       "   '-': 0.0},\n",
       "  'Feature3': {'A': 0.8509033378347781,\n",
       "   'C': 0.1490966621652219,\n",
       "   'D': 0.0,\n",
       "   'E': 0.0,\n",
       "   'F': 0.0,\n",
       "   'G': 0.0,\n",
       "   'H': 0.0,\n",
       "   'I': 0.0,\n",
       "   'K': 0.0,\n",
       "   'L': 0.0,\n",
       "   'M': 0.0,\n",
       "   'N': 0.0,\n",
       "   'P': 0.0,\n",
       "   'Q': 0.0,\n",
       "   'R': 0.0,\n",
       "   'S': 0.0,\n",
       "   'T': 0.0,\n",
       "   'V': 0.0,\n",
       "   'W': 0.0,\n",
       "   'Y': 0.0,\n",
       "   '-': 0.0}},\n",
       " 'N1': {'Feature1': {'A': 0.0,\n",
       "   'C': 0.0,\n",
       "   'D': 0.0,\n",
       "   'E': 0.0,\n",
       "   'F': 0.0,\n",
       "   'G': 0.5105161855728779,\n",
       "   'H': 0.0,\n",
       "   'I': 0.0,\n",
       "   'K': 0.0,\n",
       "   'L': 0.0,\n",
       "   'M': 0.0,\n",
       "   'N': 0.0,\n",
       "   'P': 0.0,\n",
       "   'Q': 0.0,\n",
       "   'R': 0.0,\n",
       "   'S': 0.0,\n",
       "   'T': 0.0,\n",
       "   'V': 0.0,\n",
       "   'W': 0.0,\n",
       "   'Y': 0.489483814427122,\n",
       "   '-': 0.0},\n",
       "  'Feature2': {'A': 0.0,\n",
       "   'C': 0.0,\n",
       "   'D': 0.0,\n",
       "   'E': 0.0,\n",
       "   'F': 0.0,\n",
       "   'G': 0.5105161855728779,\n",
       "   'H': 0.0,\n",
       "   'I': 0.0,\n",
       "   'K': 0.0,\n",
       "   'L': 0.0,\n",
       "   'M': 0.0,\n",
       "   'N': 0.0,\n",
       "   'P': 0.489483814427122,\n",
       "   'Q': 0.0,\n",
       "   'R': 0.0,\n",
       "   'S': 0.0,\n",
       "   'T': 0.0,\n",
       "   'V': 0.0,\n",
       "   'W': 0.0,\n",
       "   'Y': 0.0,\n",
       "   '-': 0.0},\n",
       "  'Feature3': {'A': 0.744741907213561,\n",
       "   'C': 0.25525809278643896,\n",
       "   'D': 0.0,\n",
       "   'E': 0.0,\n",
       "   'F': 0.0,\n",
       "   'G': 0.0,\n",
       "   'H': 0.0,\n",
       "   'I': 0.0,\n",
       "   'K': 0.0,\n",
       "   'L': 0.0,\n",
       "   'M': 0.0,\n",
       "   'N': 0.0,\n",
       "   'P': 0.0,\n",
       "   'Q': 0.0,\n",
       "   'R': 0.0,\n",
       "   'S': 0.0,\n",
       "   'T': 0.0,\n",
       "   'V': 0.0,\n",
       "   'W': 0.0,\n",
       "   'Y': 0.0,\n",
       "   '-': 0.0}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = gp.motifProbsFromInference(distrib, inference)\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Charlie - below are some of the things you will probably need to implement for your analysis. These would be in addition to setting up parsing alignment data to the appropriate input file format. It would probably be helpful want to make simple examples of this here with basic data that you can extend to work with your datasets. I can help with any of this, but thought it would be better for you if you had control over how it was all done.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating holdout train/test sets from a full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparision between jointly inferring motif positions with *2k* latent states vs. independently inferring two positions, each with *k* latent states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "a0c94fc6a065e1544b277cf790c4095db72a11be29cfda401c5045b27b0370ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
